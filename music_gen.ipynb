{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "tf.enable_eager_execution()\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import functools\n",
    "import util\n",
    "import matplotlib.pyplot as plt\n",
    "import __init__ as util1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('data/irish.abc').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx= {u:i for i,u in enumerate(vocab)}\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '\"' :   3,\n",
      "  '#' :   4,\n",
      "  \"'\" :   5,\n",
      "  '(' :   6,\n",
      "  ')' :   7,\n",
      "  ',' :   8,\n",
      "  '-' :   9,\n",
      "  '.' :  10,\n",
      "  '/' :  11,\n",
      "  '0' :  12,\n",
      "  '1' :  13,\n",
      "  '2' :  14,\n",
      "  '3' :  15,\n",
      "  '4' :  16,\n",
      "  '5' :  17,\n",
      "  '6' :  18,\n",
      "  '7' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'X:1\\nT:Alexand' ---- characters mapped to int ---- > [49 22 13  0 45 22 26 67 60 79 56 69 59]\n"
     ]
    }
   ],
   "source": [
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequences = char_dataset.batch(seq_length+1,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text,target_text\n",
    "\n",
    "dataset = sequences.map(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 49 ('X')\n",
      "  expected output: 22 (':')\n",
      "Step    1\n",
      "  input: 22 (':')\n",
      "  expected output: 13 ('1')\n",
      "Step    2\n",
      "  input: 13 ('1')\n",
      "  expected output: 0 ('\\n')\n",
      "Step    3\n",
      "  input: 0 ('\\n')\n",
      "  expected output: 45 ('T')\n",
      "Step    4\n",
      "  input: 45 ('T')\n",
      "  expected output: 22 (':')\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    for i,(input_idx,target_idx) in enumerate(zip(input_example[:5], target_example[:5] )):\n",
    "        print(\"Step {:4d}\".format(i))\n",
    "        print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "        print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "steps_per_epoch = examples_per_epoch//batch_size\n",
    "\n",
    "buffer_size = 10000\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define RNN (LSTM) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM = tf.keras.layers.CuDNNLSTM\n",
    "LSTM = functools.partial(LSTM,return_sequences=True,recurrent_initializer='glorot_uniform',stateful=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size,embedding_dim,rnn_units,batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size,embedding_dim,\n",
    "                                 batch_input_shape=[batch_size,None]),\n",
    "        LSTM(rnn_units),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(len(vocab),embedding_dim,rnn_units,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           21248     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (64, None, 1024)          5251072   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 83)            85075     \n",
      "=================================================================\n",
      "Total params: 5,357,395\n",
      "Trainable params: 5,357,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 83) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1): \n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.multinomial(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75, 56, 30, 19, 78, 36, 24, 11, 51, 39, 63, 74,  8,  0, 62, 76, 32,\n",
       "       25,  8, 16, 18, 33, 25, 30, 79, 42, 19, 62, 78,  0,  4, 21, 37, 16,\n",
       "       69, 47, 54, 12, 77, 73, 74, 35, 52, 48, 82, 31, 82, 41, 38, 42, 40,\n",
       "       70, 37, 79, 25, 48, 18, 77, 19, 37, 27, 13, 21,  5, 32, 32, 43,  0,\n",
       "       51, 74, 45, 13, 42, 36, 19, 34, 13, 31, 50, 58, 60, 73, 34, 27, 35,\n",
       "       50, 16,  0, 43, 20, 19,  4, 35,  6, 34, 25, 33, 79, 57, 36])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " \"2 gfed|cAeA fAed|cdef gfef|!\\ngBB2 gBaB|gBB2 gfed|cdef gfec|dfec d2:|!\\n\\nX:68\\nT:Dillon's Fancy\\nZ: id:d\"\n",
      "\n",
      "Next Char Predictions: \n",
      " \"taE7wK=/ZNhs,\\nguG>,46H>ExQ7gw\\n#9L4nV^0vrsJ[W|F|PMQOoLx>W6v7LB19'GGR\\nZsT1QK7I1FYcerIBJY4\\nR87#J(I>HxbK\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 83)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.4190216\n"
     ]
    }
   ],
   "source": [
    "def lossi(labels,logits):\n",
    "    return tf.keras.backend.sparse_categorical_crossentropy(labels,logits,from_logits=True)\n",
    "\n",
    "example_batch_loss = lossi(target_example_batch,example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "\n",
    "checkpoint_dir = './training_chkponts'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,\"ckpt_\")\n",
    "\n",
    "history = []\n",
    "# plotter = util1.PeriodicPlotter(sec=1,xlabel='Iterations',ylabel='Loss')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    hidden = model.reset_states()\n",
    "    \n",
    "#     custom_msg = util1.custom_progress_text(\"Loss : %(loss)2.2f\")\n",
    "#     bar = util1.create_progress_bar(custom_msg)\n",
    "    for inp, target in (dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            lossia = lossi(target,model(inp))\n",
    "            grads = tape.gradient(lossia,model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "            history.append(lossia.numpy().mean())\n",
    "#             custom_msg.update_mapping(loss=history[-1])\n",
    "#             plotter.plot(history)\n",
    "    model.save_weights(checkpoint_prefix.format(epoch=epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.418793,\n",
       " 4.3752522,\n",
       " 3.780592,\n",
       " 3.76109,\n",
       " 3.6996508,\n",
       " 3.547746,\n",
       " 3.4951887,\n",
       " 3.4046812,\n",
       " 3.373907,\n",
       " 3.3902133,\n",
       " 3.464433,\n",
       " 3.3601978,\n",
       " 3.4228723,\n",
       " 3.3167646,\n",
       " 3.3637993,\n",
       " 3.4170356,\n",
       " 3.3419876,\n",
       " 3.3444624,\n",
       " 3.3420892,\n",
       " 3.390226,\n",
       " 3.3628933,\n",
       " 3.3801916,\n",
       " 3.3537023,\n",
       " 3.2436635,\n",
       " 3.307915,\n",
       " 3.2845602,\n",
       " 3.333327,\n",
       " 3.2732892,\n",
       " 3.2140276,\n",
       " 3.235311,\n",
       " 3.8831065,\n",
       " 3.731568,\n",
       " 3.435525,\n",
       " 3.088342,\n",
       " 3.113435,\n",
       " 3.0615542,\n",
       " 3.100753,\n",
       " 3.03721,\n",
       " 3.067346,\n",
       " 2.918993,\n",
       " 2.9774315,\n",
       " 2.8924835,\n",
       " 2.880531,\n",
       " 2.9288635,\n",
       " 2.8237922,\n",
       " 2.8320215,\n",
       " 2.835042,\n",
       " 2.8036416,\n",
       " 2.7438953,\n",
       " 2.7130022,\n",
       " 2.737503,\n",
       " 2.7120583,\n",
       " 2.666442,\n",
       " 2.63426,\n",
       " 2.6001081,\n",
       " 2.6264374,\n",
       " 2.530113,\n",
       " 2.516898,\n",
       " 2.492437,\n",
       " 2.492936,\n",
       " 2.4953377,\n",
       " 2.359719,\n",
       " 2.4450073,\n",
       " 2.4236479,\n",
       " 2.4038906,\n",
       " 2.3441515,\n",
       " 2.304076,\n",
       " 2.303994,\n",
       " 2.3492954,\n",
       " 2.2239385,\n",
       " 2.2206037,\n",
       " 2.192122,\n",
       " 2.1843913,\n",
       " 2.1106339,\n",
       " 2.0891309,\n",
       " 2.084842,\n",
       " 2.1127484,\n",
       " 2.0266662,\n",
       " 2.061989,\n",
       " 2.0371702,\n",
       " 2.0219824,\n",
       " 2.0112062,\n",
       " 1.9472604,\n",
       " 1.9306308,\n",
       " 1.9230396,\n",
       " 1.9193436,\n",
       " 1.9505578,\n",
       " 1.8707314,\n",
       " 1.9093878,\n",
       " 1.8660861,\n",
       " 1.9861846,\n",
       " 1.8136542,\n",
       " 1.8478616,\n",
       " 1.9003917,\n",
       " 1.7996134,\n",
       " 1.8000171,\n",
       " 1.8347205,\n",
       " 1.8211181,\n",
       " 1.7477356,\n",
       " 1.8412547,\n",
       " 1.8115848,\n",
       " 1.7693592,\n",
       " 1.758381,\n",
       " 1.748116,\n",
       " 1.7484833,\n",
       " 1.7675433,\n",
       " 1.717927,\n",
       " 1.7270231,\n",
       " 1.7324408,\n",
       " 1.7451526,\n",
       " 1.7136399,\n",
       " 1.7797121,\n",
       " 1.6998489,\n",
       " 1.7020578,\n",
       " 1.6874952,\n",
       " 1.6704612,\n",
       " 1.6875615,\n",
       " 1.6767234,\n",
       " 1.7151648,\n",
       " 1.6398544,\n",
       " 1.6708887,\n",
       " 1.6196301,\n",
       " 1.6574204,\n",
       " 1.6390246,\n",
       " 1.5957446,\n",
       " 1.6137005,\n",
       " 1.5743893,\n",
       " 1.553662,\n",
       " 1.597152,\n",
       " 1.6828246,\n",
       " 1.6231778,\n",
       " 1.6660305,\n",
       " 1.6219193,\n",
       " 1.5944916,\n",
       " 1.595949,\n",
       " 1.6101209,\n",
       " 1.5824124,\n",
       " 1.6179215,\n",
       " 1.6547103,\n",
       " 1.6312631,\n",
       " 1.564317,\n",
       " 1.6119161,\n",
       " 1.5836581,\n",
       " 1.5421368,\n",
       " 1.6230817,\n",
       " 1.5741608,\n",
       " 1.5644122,\n",
       " 1.5745181,\n",
       " 1.4834534,\n",
       " 1.550448,\n",
       " 1.5120872,\n",
       " 1.6012106,\n",
       " 1.5657883,\n",
       " 1.5871953,\n",
       " 1.532778,\n",
       " 1.5453312,\n",
       " 1.541123,\n",
       " 1.4945471,\n",
       " 1.521516,\n",
       " 1.5185093,\n",
       " 1.4872696,\n",
       " 1.5123829,\n",
       " 1.517784,\n",
       " 1.5004734,\n",
       " 1.5278636,\n",
       " 1.4975604,\n",
       " 1.4977368,\n",
       " 1.5195701,\n",
       " 1.5203788,\n",
       " 1.5287433,\n",
       " 1.4779685,\n",
       " 1.501927,\n",
       " 1.5098385,\n",
       " 1.4885092,\n",
       " 1.5463351,\n",
       " 1.4749172,\n",
       " 1.4587125,\n",
       " 1.5357481,\n",
       " 1.4562443,\n",
       " 1.5141083,\n",
       " 1.4350591,\n",
       " 1.5193714,\n",
       " 1.4675477,\n",
       " 1.4285523,\n",
       " 1.4745101,\n",
       " 1.4254373,\n",
       " 1.4675577,\n",
       " 1.4557658,\n",
       " 1.498993,\n",
       " 1.4337238,\n",
       " 1.4809626,\n",
       " 1.4177294,\n",
       " 1.4420131,\n",
       " 1.5052137,\n",
       " 1.4704709,\n",
       " 1.4540464,\n",
       " 1.4770066,\n",
       " 1.4609821,\n",
       " 1.4710559,\n",
       " 1.4802649,\n",
       " 1.4508293,\n",
       " 1.4555544,\n",
       " 1.4341803,\n",
       " 1.4211779,\n",
       " 1.4787271,\n",
       " 1.3963492,\n",
       " 1.3970535,\n",
       " 1.3972708,\n",
       " 1.3692833,\n",
       " 1.4173329,\n",
       " 1.4263437,\n",
       " 1.4036545,\n",
       " 1.3441575,\n",
       " 1.3851328,\n",
       " 1.356874,\n",
       " 1.4060159,\n",
       " 1.407375,\n",
       " 1.4090804,\n",
       " 1.3880033,\n",
       " 1.3857236,\n",
       " 1.3951862,\n",
       " 1.394588,\n",
       " 1.3996603,\n",
       " 1.4131386,\n",
       " 1.3927861,\n",
       " 1.4163544,\n",
       " 1.4002625,\n",
       " 1.4017371,\n",
       " 1.3786955,\n",
       " 1.4153022,\n",
       " 1.4042447,\n",
       " 1.4148446,\n",
       " 1.3455176,\n",
       " 1.429792,\n",
       " 1.4188675,\n",
       " 1.4088166,\n",
       " 1.448573,\n",
       " 1.346922,\n",
       " 1.3962283,\n",
       " 1.4098175,\n",
       " 1.3619152,\n",
       " 1.3162576,\n",
       " 1.3786752,\n",
       " 1.3496891,\n",
       " 1.356936,\n",
       " 1.3533193,\n",
       " 1.3141074,\n",
       " 1.3326718,\n",
       " 1.3961539,\n",
       " 1.3428079,\n",
       " 1.3022412,\n",
       " 1.361383,\n",
       " 1.3140358,\n",
       " 1.3435423,\n",
       " 1.3291428,\n",
       " 1.3294799,\n",
       " 1.3910527,\n",
       " 1.3645989,\n",
       " 1.347565,\n",
       " 1.380369,\n",
       " 1.3480356,\n",
       " 1.3670578,\n",
       " 1.3088052,\n",
       " 1.2924713,\n",
       " 1.3578371,\n",
       " 1.3240542,\n",
       " 1.3501352,\n",
       " 1.3023409,\n",
       " 1.3691477,\n",
       " 1.3686264,\n",
       " 1.3437991,\n",
       " 1.3156006,\n",
       " 1.302699,\n",
       " 1.3504345,\n",
       " 1.3277093,\n",
       " 1.344924,\n",
       " 1.3311605,\n",
       " 1.2990726,\n",
       " 1.27063,\n",
       " 1.2699053,\n",
       " 1.2762957,\n",
       " 1.3042752,\n",
       " 1.3090026,\n",
       " 1.3198835,\n",
       " 1.3342441,\n",
       " 1.3298868,\n",
       " 1.332039,\n",
       " 1.2689029,\n",
       " 1.2848853,\n",
       " 1.2873578,\n",
       " 1.2740003,\n",
       " 1.2715671,\n",
       " 1.3039076,\n",
       " 1.2882712,\n",
       " 1.3006847,\n",
       " 1.2895361,\n",
       " 1.3262436,\n",
       " 1.2990795,\n",
       " 1.2931931,\n",
       " 1.2604976]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            21248     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (1, None, 1024)           5251072   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 83)             85075     \n",
      "=================================================================\n",
      "Total params: 5,357,395\n",
      "Trainable params: 5,357,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, generation_length=1000):\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in (range(generation_length)):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy() # TODO \n",
    "        \n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id]) # TODO \n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = generate_text(model, start_string=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.play_generated_song(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
